{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45eacb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from bertviz import model_view\n",
    "import jsonlines\n",
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from constants import ENTITY_START_MARKER, ENTITY_END_MARKER\n",
    "from data_loader import  DrugSynergyDataModule, make_fixed_length\n",
    "from model import RelationExtractor, load_model\n",
    "from preprocess import create_dataset\n",
    "from utils import construct_row_id_idx_mapping, set_seed, write_error_analysis_file\n",
    "\n",
    "from streamlit_single_relation_app import classify_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5571cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/vijay/drug-synergy-models/checkpoints_more_data_with_drug_tokens_paragraph_2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da6cc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, metadata = load_model(checkpoint_path, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec55ee73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2377"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens([ENTITY_START_MARKER, ENTITY_END_MARKER])\n",
    "drugs = open(\"drugs.txt\").read().lower().split()\n",
    "tokenizer.add_tokens(drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84c9b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_text = \"Various cutaneous side-effects have been reported with anti-melanoma systemic therapies. This study investigated the changes in melanocytic lesion pigmentation in patients on four different therapies. ### methods We analysed the serial dermatoscopic photographs of atypical melanocytic lesions taken from patients with advanced metastatic melanoma on four different systemic therapies ( selective BRAF-inhibitor monotherapy , <<m>> dabrafenib <</m>> combined with <<m>> trametinib <</m>> [ D&T ] , anti-programmed cell death protein 1 [ anti-PD1 ] therapies , and anti-PD1 combined with ipilimumab ) seen from February 2013 to May 2016 . We compared these changes with the melanocytic lesions of 10 control patients. ### results In the control group, 19% of naevi lightened, 64% did not change and 17% darkened. Only the BRAF inhibitor group showed more darkened lesions than controls (37%, P < 0.001). Meanwhile, there were more lightened naevi in the D&T therapy group (86%, P < 0.001) as well as the anti-PD1 and ipilimumab groups (59%, P < 0.001) than controls. Patients on anti-PD1 monotherapy had more lightened (49%) and fewer darkened naevi (9%) than controls, but differences were not significant. ### conclusions Our study showed that different anti-melanoma systemic therapies have different effects on the pigmentation of melanocytic lesions. BRAF inhibitor may have the propensity to cause darkening while D&T therapy and anti-PD1 caused lightening compared with controls. The findings emphasise the importance of regular dermatological monitoring in specialised clinics for patients on anti-melanoma systemic therapy. Clinicians should expect changes in the global pigmentation of melanocytic lesions but be suspicious of lesions with structural changes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7f277a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(message_text, return_tensors='pt')\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9747cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = make_fixed_length(tokens, metadata.max_seq_length, padding_value = \"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b2015d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output, attention = classify_message(message_text, model, tokenizer, metadata.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ea87561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted label': 1, 'relation probabilities': [0.3897, 0.6103]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f029ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_attention_layer = attention[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d686de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_keep_nth_head(attention_layer, head_idxs, seq_length):\n",
    "    return attention_layer[:, head_idxs, :seq_length, :seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "139adfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 512, 512])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "660d36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_pruned = (only_keep_nth_head(attention[0], list(range(12)), len(tokens)), only_keep_nth_head(attention[1], list(range(12)), len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e8e2785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 371, 371])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_pruned[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbfc8191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69, 74]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, v in enumerate(tokens) if v == \"<<m>>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58778931",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token_idxs = [i for i, v in enumerate(tokens) if v == \"<<m>>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afd5c4d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing attention head 0 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "melanoma (344)\t\t\t0.016837473958730698\n",
      "melanoma (281)\t\t\t0.013962700963020325\n",
      "melanoma (56)\t\t\t0.012813893146812916\n",
      "braf (64)\t\t\t0.010214664973318577\n",
      "[SEP] (370)\t\t\t0.009979208000004292\n",
      ") (249)\t\t\t\t0.009928843006491661\n",
      "melanoma (12)\t\t\t0.009653931483626366\n",
      ") (260)\t\t\t\t0.009097267873585224\n",
      "ipilimumab (219)\t\t0.008931697346270084\n",
      ") (231)\t\t\t\t0.008475184440612793\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 1 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "different (59)\t\t\t0.06901772320270538\n",
      "different (31)\t\t\t0.04565685987472534\n",
      "different (278)\t\t\t0.03442399948835373\n",
      "different (285)\t\t\t0.03403519093990326\n",
      "analysed (39)\t\t\t0.025331266224384308\n",
      "<<m>> (74)\t\t\t0.024301541969180107\n",
      "<<m>> (69)\t\t\t0.016506988555192947\n",
      "taken (50)\t\t\t0.013258477672934532\n",
      "differences (265)\t\t0.012552227824926376\n",
      "photographs (44)\t\t0.012253135442733765\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 2 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "<<m>> (74)\t\t\t0.01831836998462677\n",
      "investigated (18)\t\t0.015243141911923885\n",
      "controls (262)\t\t\t0.0137331523001194\n",
      "[CLS] (0)\t\t\t0.013126532547175884\n",
      "] (95)\t\t\t\t0.011991742998361588\n",
      "controls (233)\t\t\t0.011269409209489822\n",
      "64 (147)\t\t\t0.0104900524020195\n",
      "with (9)\t\t\t0.009924023412168026\n",
      "systemic (13)\t\t\t0.0093605387955904\n",
      "analysed (39)\t\t\t0.009109389036893845\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 3 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "different (59)\t\t\t0.10643985122442245\n",
      "different (31)\t\t\t0.08480513840913773\n",
      "different (285)\t\t\t0.08370178192853928\n",
      "different (278)\t\t\t0.07637540996074677\n",
      "importance (328)\t\t0.0293789803981781\n",
      "taken (50)\t\t\t0.021183297038078308\n",
      "analysed (39)\t\t\t0.01873641461133957\n",
      "##ocytic (48)\t\t\t0.011206199415028095\n",
      "dabrafenib (70)\t\t\t0.00909342709928751\n",
      "##ocytic (23)\t\t\t0.0090056536719203\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 4 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "cell (86)\t\t\t0.06833404302597046\n",
      "lesions (49)\t\t\t0.05427813529968262\n",
      "anti (83)\t\t\t0.052265722304582596\n",
      "<<m>> (74)\t\t\t0.042897000908851624\n",
      "##og (332)\t\t\t0.0342746376991272\n",
      "<<m>> (69)\t\t\t0.03416698798537254\n",
      "dabrafenib (70)\t\t\t0.030467431992292404\n",
      "different (59)\t\t\t0.029639195650815964\n",
      "braf (64)\t\t\t0.026601804420351982\n",
      "had (242)\t\t\t0.02573825977742672\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 5 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "anti (83)\t\t\t0.15153753757476807\n",
      "anti (91)\t\t\t0.12040252238512039\n",
      "( (62)\t\t\t\t0.09821365028619766\n",
      "dabrafenib (70)\t\t\t0.07276017963886261\n",
      "anti (279)\t\t\t0.05079706758260727\n",
      "had (242)\t\t\t0.046733614057302475\n",
      "anti (99)\t\t\t0.043296195566654205\n",
      "cell (86)\t\t\t0.03722043335437775\n",
      "trametinib (75)\t\t\t0.03423352167010307\n",
      "different (59)\t\t\t0.03255552798509598\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 6 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "dabrafenib (70)\t\t\t0.8368335962295532\n",
      "( (246)\t\t\t\t0.03406986594200134\n",
      "<<m>> (69)\t\t\t0.03358573839068413\n",
      "trametinib (75)\t\t\t0.01897699199616909\n",
      "anti (91)\t\t\t0.01685882918536663\n",
      "<</m>> (71)\t\t\t0.016426805406808853\n",
      "( (62)\t\t\t\t0.010026471689343452\n",
      "anti (83)\t\t\t0.005704799201339483\n",
      "cell (86)\t\t\t0.0034718168899416924\n",
      "( (221)\t\t\t\t0.0026849289424717426\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 7 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "atypical (46)\t\t\t0.09479714930057526\n",
      "different (59)\t\t\t0.06112630292773247\n",
      "anti (83)\t\t\t0.029011938720941544\n",
      "##oscopic (43)\t\t\t0.02586469054222107\n",
      "anti (91)\t\t\t0.024436593055725098\n",
      "different (278)\t\t\t0.02344890683889389\n",
      "braf (64)\t\t\t0.02225922793149948\n",
      "different (285)\t\t\t0.020111866295337677\n",
      "anti (99)\t\t\t0.019953332841396332\n",
      "differences (265)\t\t0.019841883331537247\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 8 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "different (59)\t\t\t0.03205229714512825\n",
      "( (62)\t\t\t\t0.023022862151265144\n",
      "lesions (49)\t\t\t0.022615810856223106\n",
      "on (57)\t\t\t\t0.018241241574287415\n",
      "and (98)\t\t\t0.017349237576127052\n",
      "different (31)\t\t\t0.015572897158563137\n",
      "taken (50)\t\t\t0.015332400798797607\n",
      "different (278)\t\t\t0.013401076197624207\n",
      "with (73)\t\t\t0.012868324294686317\n",
      "different (285)\t\t\t0.012563042342662811\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 9 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "cell (86)\t\t\t0.1169225424528122\n",
      "different (59)\t\t\t0.06231844052672386\n",
      "different (31)\t\t\t0.0338241271674633\n",
      "##ocytic (48)\t\t\t0.027892572805285454\n",
      "##ocytic (122)\t\t\t0.019461000338196754\n",
      "braf (64)\t\t\t0.018271949142217636\n",
      "##ocytic (23)\t\t\t0.017936022952198982\n",
      "different (278)\t\t\t0.017441097646951675\n",
      "different (285)\t\t\t0.016411192715168\n",
      "protein (88)\t\t\t0.013075442053377628\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 10 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "different (59)\t\t\t0.1750820130109787\n",
      "different (31)\t\t\t0.055090948939323425\n",
      "with (73)\t\t\t0.049195628613233566\n",
      "different (278)\t\t\t0.038161952048540115\n",
      "with (53)\t\t\t0.03357335552573204\n",
      "different (285)\t\t\t0.03255666419863701\n",
      "9 (258)\t\t\t\t0.023138469085097313\n",
      "on (57)\t\t\t\t0.019748244434595108\n",
      "with (104)\t\t\t0.012343890964984894\n",
      "braf (64)\t\t\t0.011326141655445099\n",
      "\n",
      "\n",
      "\n",
      "Showing attention head 11 in transformer layer 0\n",
      "Query entity: entity marker before \"dabrafenib\" (69)\n",
      "===================================================\n",
      "Subword\t\t\t|\tAttention weight\n",
      "---------------------------------------------------\n",
      "( (62)\t\t\t\t0.2046186476945877\n",
      "<<m>> (69)\t\t\t0.20064279437065125\n",
      "dabrafenib (70)\t\t\t0.15090423822402954\n",
      "( (246)\t\t\t\t0.06394558399915695\n",
      ", (68)\t\t\t\t0.05513221397995949\n",
      "had (242)\t\t\t0.04102356359362602\n",
      "cell (86)\t\t\t0.03469381108880043\n",
      "monotherapy (67)\t\t0.027136962860822678\n",
      "1 (89)\t\t\t\t0.025208989158272743\n",
      "trametinib (75)\t\t\t0.022345729172229767\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_attended_words(attention_tensors, query_token_idx, layer_idx, attn_head_idx, num_words_to_show=10):\n",
    "    top_self_attentions = np.argsort(-attention_tensors[layer_idx][0][attn_head_idx][query_token_idx].detach())[:num_words_to_show]\n",
    "    for other_token_idx in top_self_attentions:\n",
    "        word = f\"{tokens[other_token_idx]} ({other_token_idx})\"\n",
    "        if len(word) <= 7:\n",
    "            num_tabs = 4\n",
    "        elif len(word) >= 16:\n",
    "            num_tabs = 2\n",
    "        else:\n",
    "            num_tabs = 3\n",
    "        tabs = \"\".join([\"\\t\" for _ in range(num_tabs)])\n",
    "        print(f\"{tokens[other_token_idx]} ({other_token_idx}){tabs}{attention_pruned[layer_idx][0][attn_head_idx][start][other_token_idx]}\")\n",
    "\n",
    "TRANSFORMER_LAYER_IDX = 0\n",
    "ATTENTION_HEAD_IDX = 4\n",
    "for attention_head in range(12):\n",
    "    start = start_token_idxs[0]\n",
    "    print(f\"Showing attention head {attention_head} in transformer layer {TRANSFORMER_LAYER_IDX}\")\n",
    "    print(f\"Query entity: entity marker before \\\"{tokens[start+1]}\\\" ({start})\")\n",
    "    print(\"===================================================\")\n",
    "    print(f\"Subword\\t\\t\\t|\\tAttention weight\\n---------------------------------------------------\")\n",
    "    print_top_attended_words(attention_pruned, start, TRANSFORMER_LAYER_IDX, attention_head)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b505b04",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# model_view(attention_pruned, tokens[:metadata.max_seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f1742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
